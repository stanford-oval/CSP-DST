experiment ?=
experiment_dialogs ?=

# all dataset names to process
all_names = eval
eval_set_name = eval

dlg_side = user

update_canonical_flags ?= --skip
process_schemaorg_flags ?= --manual

skip_translation=false
skip_po=true

# 23 languages
subset_languages = en fa it zh hr ja ko ru es sv tr hi fi fr de pl ar vi ji pt el he si ta

# 10 languages
oht_languages = ar de es fa fi it ja pl tr zh
oht_languages_plus_en = en ar de es fa fi it ja pl tr zh

marian_oht_languages = ar de es fi it pl zh
gt_oht_languages = fa ja tr

# bootstrap languages
# boot_languages = de fa fi ja tr
boot_languages = ar de es fa fi it ja pl tr zh

missing_tsv_values = tt:phone_number tt:number

missing_manifest_languages = ar fa
missing_manifest_strings = org.schema.Hotel:Place_address_postalCode org.schema.Hotel:Hotel_address_postalCode org.schema.Restaurant:Restaurant_servesCuisine org.schema.Restaurant:Restaurant_address_streetAddress org.schema.Restaurant:Restaurant_address_postalCode org.schema.Restaurant:Restaurant_address_addressLocality
missing_manifest_entities = org.schema.Restaurant:Restaurant org.schema.Hotel:LocationFeatureSpecification

train-synthetic-expand-factor := 2
train-quoted-paraphrasing-expand-factor := 4
train-no-quote-paraphrasing-expand-factor := 3
eval-synthetic-expand-factor := 1
eval-quoted-paraphrasing-expand-factor := 1
eval-no-quote-paraphrasing-expand-factor := 1
test-synthetic-expand-factor := 1
test-quoted-paraphrasing-expand-factor := 1
test-no-quote-paraphrasing-expand-factor := 1

train_output_per_example = 1
evaltest_output_per_example = 1

eval_restaurants_oht_size = 377
eval_restaurants_v2_oht_size = 377
eval_hotels_oht_size = 330
eval_hotels_v2_oht_size = 330

train-subset-param-set = 0-0.8
evaltest-subset-param-set = 0.2-1


crawl_target_size = 100

remove_duplicate_sents = false
replace_ids = false
preprocess_paraphrased = false


# for contextual datasets uncomment following lines
contextual = --contextual
#handle-heuristics = --handle-heuristics
num_columns=4
#parameter-datasets=dlg-shared-parameter-datasets.tsv
parameter-datasets=shared-parameter-datasets.tsv


# for single-turn datasets uncomment following lines
#contextual =
#handle-heuristics = --handle-heuristics
#num_columns=3
#parameter-datasets=$(experiment)/parameter-datasets.tsv


#replace-numbers=--replace-numbers
replace-numbers=
#replace-locations=--replace-locations
replace-locations=

#aug_target_language=dlgthingtalk

aug_target_language=thingtalk


# paraphrase
num_paraphrases = 4
cut_off = 2

#eval_oracle = --oracle
eval_oracle =

val_batch_size=800
temperature=0.2

default_augment_train_hparams =  --requotable --target-language $(aug_target_language) $(contextual) --thingpedia $(experiment)/schema.tt --parameter-datasets $(parameter-datasets) --synthetic-expand-factor $(train-synthetic-expand-factor) --quoted-paraphrasing-expand-factor $(train-quoted-paraphrasing-expand-factor) --no-quote-paraphrasing-expand-factor $(train-no-quote-paraphrasing-expand-factor) --subset-param-set $(train-subset-param-set) --sampling-type uniform --quoted-fraction 0.0 $(replace-numbers) $(replace-locations) --parallelize $(parallel)


default_augment_evaltest_hparams =  --requotable --target-language $(aug_target_language) $(contextual) --thingpedia $(experiment)/schema.tt --parameter-datasets $(parameter-datasets) --synthetic-expand-factor 1 --quoted-paraphrasing-expand-factor 1 --no-quote-paraphrasing-expand-factor 1 --subset-param-set $(evaltest-subset-param-set) --sampling-type random --quoted-fraction 0.0 $(replace-numbers) $(replace-locations) --override-flags S --parallelize $(parallel)

default_translation_hparams = --val_batch_size $(val_batch_size) --temperature $(temperature) --repetition_penalty 1.0

default_translation_hparams_sts = --replace_qp --force_replace_qp  --temperature $(temperature) --repetition_penalty 1.0


default_train_new_hparams =  --model $(seq2seq_class) --pretrained_model $(pretrained_model) --train_batch_tokens $(train_batch_tokens) --lr_multiply $(lr_multiply) --warmup $(warmup) --gradient_accumulation_steps $(gas) $(train_specific_args)


default_train_bootleg_hparams =   --model $(seq2seq_class) --pretrained_model $(pretrained_model) --train_batch_tokens $(train_batch_tokens) --do_ned --ned_retrieve_method bootleg --ned_features type_id type_prob --ned_features_size 2 2 --ned_features_default_val 0 1.0 --almond_domains $(almond_domains) --lr_multiply $(lr_multiply) --warmup $(warmup) --gradient_accumulation_steps $(gas) --bootleg_model $(bootleg_model) --no_fast_tokenizer --bootleg_post_process_types --add_types_to_text append $(train_specific_args)


default_generate_hparams = --memsize 8500 --subsample_thingpedia 1 --synthetic_expand_factor 1 --quoted_paraphrase_expand_factor 25 --noquote_paraphrase_expand_factor 1 --target_pruning_size 50

calib_is_params = --is_correct_params '' --is_probably_correct_params '' --is_ood_params ''


default_bootleg_hparams = $(bootleg_specific_args)

default_eval_hparams = --overwrite --evaluate valid

default_sts_masked_hparams = --infill_text --num_text_spans 1 --temperature 0.4 --repetition_penalty 1.0 --num_samples 1 --batch_size 64  --skip_heuristics \
                        --att_pooling mean --id_column 0  --input_column 1 --gold_column 1 --thingtalk_column 2 --output_example_ids_too --task translate --no_fast_tokenizer


default_sts_round_trip_hparams = --temperature 0.4 --repetition_penalty 1.0 --num_samples 1 --batch_size 64  --skip_heuristics \
                        --att_pooling mean --id_column 0  --input_column 1 --gold_column 1 --output_attentions --output_example_ids_too --task translate --output_attentions --no_fast_tokenizer



submit_args = --owner $(owner) --project $(project) --experiment $(experiment) --image $(image)


image = 932360549041.dkr.ecr.us-west-2.amazonaws.com/genie-toolkit-kf:qa.2


genienlp_version = c30bcf85260adcd28cb581d3e7096fc877bbe31f

genie_version = fb8b240bae41c7eb1d1ad2a15e91a325f809a91b

#workdir_version = master
#workdir_repo = git@github.com:stanford-oval/genie-workdirs.git

workdir_version = 87b51737799c42dcb32a8986a28bdf58908c9c5c
workdir_repo = git@github.com:stanford-oval/thingpedia-common-devices.git

thingpedia_developer_key = 88c03add145ad3a3aa4074ffa828be5a391625f9d4e1d0b034b445f18c595656


all_versions = --genienlp_version $(genienlp_version) --genie_version $(genie_version) --workdir_repo $(workdir_repo) --workdir_version $(workdir_version) --thingpedia_developer_key $(thingpedia_developer_key)
all_versions_translate = --genienlp_version $(genienlp_version) --genie_version $(genie_version) --workdir_repo git@github.com:stanford-oval/genie-workdirs.git --workdir_version $(workdir_version)


paraphrase_sts_hparams = --batch_size 250 --model_name xlm-r-distilroberta-base-paraphrase-v1
filtering_sts_hparams = --filtering_metric constant --filtering_threshold 0.98

